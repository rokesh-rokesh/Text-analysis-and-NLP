# -*- coding: utf-8 -*-
"""text_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cP77z5xXjnyNCVDCrJOBOQTkrqGC3X_z
"""

import re
from itertools import chain
import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
from nltk.corpus import words
import os
import pandas as pd

nltk.download('all')



"""#1.Sentimental Analysis"""

def sentimental_analysis(f):


  # pat = re.compile(r'[^a-zA-Z ]+')
  # f = re.sub(pat," ",f.read()).lower().split()

  s1 = open('/content/sample_data/StopWords_Auditor.txt','r')
  stop1 = s1.read().lower().split()

  s2 = open('/content/sample_data/StopWords_Currencies.txt','r',encoding='iso-8859-1')
  stop2 = s2.read().replace('|','').lower().split()

  s3 = open('/content/sample_data/StopWords_DatesandNumbers.txt','r')
  stop3 = s3.read().lower().split()

  s4 = open('/content/sample_data/StopWords_Generic.txt','r')
  stop4 = s4.read().lower().split()

  s5 = open('/content/sample_data/StopWords_GenericLong.txt','r')
  stop5 = s5.read().lower().split()

  s6 = open('/content/sample_data/StopWords_Geographic.txt','r')
  stop6 = s6.read().lower().split()

  s7 = open('/content/sample_data/StopWords_Names.txt','r')
  stop7 = s7.read().lower().split()

  stop = [stop1,stop2,stop3,stop4,stop5,stop6,stop7]
  stop_words = list(chain(*stop))
  Total_Words_after_cleaning = 0
  for word in f:
      if word in stop_words:
          f.remove(word)
          Total_Words_after_cleaning += 1
      else:
          pass

  #1.2 Creating a dictionary of Positive and Negative words
  pw = open('/content/sample_data/positive_words.txt','r',encoding="utf-8")
  a = pw.read().split()
  positive_words = {'positive_word':a}
  nw = open('/content/sample_data/negative_words.txt','r',encoding="latin-1")
  b = nw.read().split()
  negative_words = {'negative_word':b}

  #1.3 Extracting Derived variables
  string = ''''''
  for j in f:
    string += " " + j
  words = word_tokenize(string)
  positive_score = 0
  negative_score = 0

  #postive and negative score
  for i in words:
    for value1 in positive_words.values():
      if i in value1:
        positive_score+=1
    for value2 in negative_words.values():
      if i in value2:
        negative_score+=1

  print("Sentimental Analysis of "+str(num))
  print("1)Positive_score:",positive_score)
  print("2)Negative_score:",negative_score)

  #Polarity Score = (Positive Score â€“ Negative Score)/ ((Positive Score + Negative Score) + 0.000001)
  Polarity_score = round((positive_score - negative_score) / ((positive_score + negative_score) + 0.000001),2)
  print("3)Polarity_score:",Polarity_score)

  #Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)
  Subjectivity_score = round((positive_score + negative_score) / ((Total_Words_after_cleaning) + 0.000001),2)
  print("4)Subjectivity_score:",Subjectivity_score)
  print("\n")

  return positive_score,negative_score,Polarity_score,Subjectivity_score

Ps,Ns,Pos,Ss = [],[],[],[]
#Main function
for num in range(37,151):
  f = open("/content/sample_data/"+str(num)+".txt",'r')
  pat = re.compile(r'[^a-zA-Z ]+')
  f = re.sub(pat," ",f.read()).lower().split()
  result = sentimental_analysis(f)
  result = list(result)
  print(result)
  Ps.append(result[0])
  Ns.append(result[1])
  Pos.append(result[2])
  Ss.append(result[3])

#Creating a dataframe for store and organize all results
df = pd.DataFrame(
    {'Positive score':Ps,
     'Negative score':Ns,
     'Polarity_score':Pos,
     'Subjectivity_score':Ss})

from google.colab import files
df.to_csv('Sentimental_Analysis_result',index=False)
files.download('Sentimental_Analysis_result')

